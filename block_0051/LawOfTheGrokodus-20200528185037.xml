<post>
  <author>LawOfTheGrokodus</author>
  <date>2020-05-28T18:50:37Z</date>
  <link>/r/TheMotte/comments/gq50mo/culture_war_roundup_for_the_week_of_may_25_2020/fs48peh/</link>
  <title>Summarizing Section 230 and Online Speech Restriction</title>
  <body>
    <div class="md">
      <p>Trump's beef with Twitter heats up: A proposed executive order seeks to limit Section 230 protections <a href="https://kateklonick.com/wp-content/uploads/2020/05/DRAFT-EO-Preventing-Online-Censorship.pdf">https://kateklonick.com/wp-content/uploads/2020/05/DRAFT-EO-Preventing-Online-Censorship.pdf</a>. I am not interested in discussing here whether Twitter is biased to the left or to the right, whether any of Trump's tweets are factually wrong or in violation of Twitter's rules, or what if anything Twitter should do about Trump.</p>
      <p>Section 230 is nearly the sole remaining component of the Communications Decency Act, a law designed to inhibit indecent and obscene material on the internet, after the rest of it got struck down for being in violation of the First Amendment. Section 230 can be read in full <a href="https://www.law.cornell.edu/uscode/text/47/230">here</a>. To pull out the most relevant part, it states that:</p>
      <blockquote>
        <p>No provider or user of an <a href="https://www.law.cornell.edu/definitions/uscode.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=47-USC-1900800046-1237841278&amp;term_occur=999&amp;term_src=title:47:chapter:5:subchapter:II:part:I:section:230">interactive computer service</a> shall be treated as the publisher or speaker of any information provided by another<a href="https://www.law.cornell.edu/definitions/uscode.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=47-USC-10252844-1237841279&amp;term_occur=999&amp;term_src=title:47:chapter:5:subchapter:II:part:I:section:230"> information content provider.</a></p>
      </blockquote>
      <p>And</p>
      <blockquote>
        <p>No provider or user of an <a href="https://www.law.cornell.edu/definitions/uscode.php?width=840&amp;height=800&amp;iframe=true&amp;def_id=47-USC-1900800046-1237841278&amp;term_occur=999&amp;term_src=title:47:chapter:5:subchapter:II:part:I:section:230">interactive computer service</a> shall be held liable on account of [...] any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected</p>
      </blockquote>
      <p>There's a ton of misconceptions about Section 230. One of the most common, coming even from folks <a href="https://twitter.com/marcorubio/status/1265442093641732096">high up</a> in the government (happy birthday, Senator Rubio!), is that it applies only to platforms, not publishers. As Eugene Volokh explains <a href="https://reason.com/2020/05/28/47-u-s-c-%C2%A7-230-and-the-publisher-distributor-platform-distinction/?utm_source=dlvr.it&amp;utm_medium=twitter">here</a>, this is pretty much ignoring that Section 230 exists. Without Section 230, indeed, only platforms which are legally prohibited from moderating are immune to liability. But the law explicitly says both that web sites aren't liable for user-generated content and that this freedom from liability is not curtailed by their moderation activities, including acting to remove constitutionally protected content.</p>
      <p>This is a very good thing. Consider: it's clearly constitutional to say that Jesus Christ is the only path to salvation and nonbelievers will burn in hell for all eternity. But if I'm running a forum or a Facebook group or subreddit for Muslims to discuss the Quran, it's pretty reasonable to allow me to ban the Christian troll who keeps spamming that members are going to hell. Pornography is constitutionally protected, but if I'm Facebook and I want to have a site that parents are okay with their kids having an account on, I'm going to want to be able to remove or at least put up barriers around pornographic content. If I have a personal site where I post my artwork and have a comment section, I should be allowed to delete the comments from some dickhead who just insults me.</p>
      <p>Without Section 230's protections, this sort of moderation would mean that I'm also liable for any illegal content that someone posts. So that Quran discussion forum? Someone posts a picture of a mosque that they don't have legal rights to, and now I can be sued. Facebook? One of the billion posts users make per day is libel. Whoops, I'm in trouble. I abandon and forget about my art page and in subsequent years some pedophile posts child porn in the comment section? Oh shit, I'm in trouble. The only safe option is to not allow any user generated content at all without individually screening and approving every part of it. And even that will only work if I'm intimately familiar with all the ways that speech can have legal issues. Maybe it's better to just not allow people to post things at all online.</p>
      <p>Where this has gotten controversial is when someone with political power feels that a website is moderating content it shouldn't, or leaving up content that it should take down. Often, this is couched in terms of fighting misinformation, or fighting political bias. But Section 230 is silent on these — "good faith" and "otherwise objectionable" are rightly very broad. Again, this is a good thing. Mandated banning misinformation can turn very, very easily into suppressing unpopular views. Often, that's used to try to compel private actors, who are not limited by the first amendment, to ban speech that the government legally cannot. Preventing political bias in moderation also has first amendment issues. If I want to make a Google group to cheer on libertarianism, prohibiting me from kicking out neo-Nazis, tankies, and ISIS supporters (how did they even find us? Why are they doing this??) restricts my rights to freedom of association.</p>
      <p>Okay, but Twitter and Facebook and the like aren't just any websites, they're so omnipresent that they're a bona vide public square. Removing someone from there, or skewing the discourse, is stifling their ability to express themselves. Honestly, I'm sympathetic to this argument. I'm a huge fan of the first amendment, and I think it is unfortunate that so much of modern discourse happens in places where, thanks to being privately owned, the first amendment doesn't apply. And network effects are real — if Twitter decided to delete all posts expressing a conservative political viewpoint, I think it would be hard to create a thriving platform that allowed them with Twitter already in the room sucking up all the oxygen. But I think a lot of the arguments along these lines aren't out of principle. The folks who say that Facebook already censors conservatives probably wouldn't want a Facebook that actually had to abide by the first amendment, full of porn, CCP shills, and with no one having any right to stop their posts from filling up with this. I might be more okay with that, but first amendment kooks like me are rare.</p>
      <p>Opposition to Section 230 is unfortunately bipartisan. Joe Biden <a href="https://www.nytimes.com/interactive/2020/01/17/opinion/joe-biden-nytimes-interview.html">has said</a> that Section 230 "immediately should be revoked." A few months ago, I attended a forum on election integrity at Georgetown University, and perhaps the highest profile speaker, one of the commissioners of the Federal Election Commission, said that she wanted to make Section 230 protections conditional on... basically them removing content she didn't like. Sorry, her position was so incoherent and totalitarian I can't really be that charitable to it. Bipartisan laws have attempted to chisel away at the protections, including Senator Graham's and Senator Feinstein's EARN IT bill and the FOSTA-SESTA package. </p>
      <p>(Continued below)</p>
    </div>
  </body>
</post>