<post>
  <author>cretan_bull</author>
  <date>2020-05-28T03:45:45Z</date>
  <link>/r/TheMotte/comments/gq50mo/culture_war_roundup_for_the_week_of_may_25_2020/fs1x1nh/</link>
  <title>Probability Theory and Stereotypes in Medicine</title>
  <body>
    <div class="md">
      <p>I am firmly of the opinion that applying probability theory correctly, with <em>all</em> the information available, is better under almost all circumstances, with exceptions requiring very strong justification.</p>
      <p>One exception is in the legal system, where there are rules about privacy, when and how the government is allowed to obtain information, and rules of evidence which restrict what information is available in a courtroom. This may reduce the accuracy of a legal verdict. For example a defendant having prior convictions could be strong Bayesian evidence. However, a principled decision has been made that only certain sorts of information can be admitted, and that particular sort of information would be "unfairly prejudicial". That's very complex topic, and I'm not familiar with all the philosophical justifications for it, but it doesn't seem completely unreasonable, either.</p>
      <p>Another exception might be where a health insurance company is only allowed to see certain sorts of information, and doesn't have access to a person's full medical history, everything they've done in their life, their genetic data, and all their family history. I'm not sure exactly what factors insurance companies are allowed to use, but I understand that it is a restricted set of information and this is done both to protect peoples' privacy and so that its "fairer" to people at higher risk. Protecting privacy doesn't seem unreasonable, but I think the second argument is quite suspect. In a sense, an insurance company having the maximal amount of information and applying that information correctly is maximally fair. If you have good nutrition, exercise regularly, work in a safe job, don't engage in risky behavior and all your grandparents lived to over 90, then having a commensurably lower premium is justified, and the more information the insurance company has the more accurately they can assess the risk and the lower your premium can go. Conversely, if you have a family history of cancer and heart disease and all sorts of worrying genetic indicators, then a higher premium is just an accurate reflection of reality. If we, as a society, decide that someone shouldn't be "punished" for having bad genes, then that properly seems like something that should be coordinated through government and a universal health care system.</p>
      <p>Respectfully, I don't think any of your examples are good ones:</p>
      <blockquote>
        <p>If the formula had an isAmerican term in it, you would probably raise an eyebrow. They could justify it by saying "Americans have different diets", but it still indicates that the doctor doesn't really know what's going on. If the blood pressure cuff in your doctor's office has a 'gamer/not gamer' setting, you have a problem.</p>
      </blockquote>
      <p>"isAmerican" isn't much information. It's even less information than "isBlack". A justification such as "Americans have different diets" is really dumb, because if you know that it's due to diet, you could get much more information by just asking the patient about their diet, or looking at other parameters associated with diet such as fitness, obesity, and insulin sensitivity. Trying to get perfect information on their diet is a red herring, the idea is to get <em>better</em> information, and getting even very imperfect information on diet would provide far more information than "isAmerican" if diet is what you're really interested in.</p>
      <p>If the blood pressure cuff has a "gamer/not gamer" setting, then I think that would be very surprising and a lot of people would be very urgently interested into doing more research into the underlying mechanism, especially since blood pressure is such a basic and important medical parameter. "isGamer" isn't very predictive 
at all, and can change radically depending on how it's defined -- for example, is a person who plays games on their phone on the way to work a gamer? If it were defined fairly strictly, in the sense of someone who spent a lot of time playing games, then I think it would provide some information, though not much, on behavior, lifestyle, age, sex and race. If the effect size of "isGamer" was large, this would be <em>really</em> concerning because "isGamer" is such a broad, low-information category; it would imply that there was something <em>really</em> important missing in the body of medical knowledge. Since it's so low-information, not only would many gamers be misclassified incorrectly in the model, but there would be many non-gamers who should be put with gamers for the model. I would expect that researchers would quickly discover underlying parameters that were much better predictors, such as sedentariness, which would both remove "isGamer" from the model and make the model far more accurate. If research didn't turn up better predictors, and it seemed that, yes, it really was the act of playing video games itself that had this effect, then that would become a huge medical mystery that would see increasingly large amounts of resources at it because it would be so surprising and important.</p>
      <blockquote>
        <p>The classic example is policing, where a Bayesian cop would treat black people as more dangerous than white people. While that might improve overall outcomes, it still punishes individual black people who are harmless and have done nothing to earn a threat response.</p>
      </blockquote>
      <p>A policeman is walking down the street and assessing people on the threat they pose, paying more attention to people they think more threatening. If one does something that might be considered suspicious, maybe they'll ignore it if it's a middle aged, white, relatively wealthy-looking woman, and aggressively investigate it if it's a young black man. Without looking at crime statistics, let's say something like that happens and a Bayesian calculation would determine a 1:500 probability that the woman was about to commit a crime, and a 1:3 chance that the black man was. 1:3 seems bad, but it's still more likely than not that the black man <em>wasn't</em> going to commit a crime. Also, there is still a normative principle that people have a presumption of innocence, and police aren't allowed to use more force than strictly necessary to arrest someone or to stop themselves or others from being injured. The problem here isn't using the information -- that's like, over 7 bits between the white woman and young black man, ignoring that would be crazy! -- but that the policeman is poorly calibrated and thinks "a crime is about to be committed" not "there is a significant chance a crime is about to be committed" and treats the black man like he is actually a criminal, ignoring that it's still actually more likely than not he's innocent. And even if a Bayesian calculation would give a 99:1 chance that the black man was about to commit a crime, he's still entitled to a presumption of innocence and the policeman is still restricted in the amount of force he can use. I repeat: our goal should be making people <em>better</em> at reasoning, not worse. Not only is this a worthy goal in itself, but telling the policeman he's not allowed to reason will inevitably fail (reason is useful -- surprise!). Since he's not good at reasoning and we're not teaching him to reason better because we're telling him he's not allowed to reason and pretending he won't, he will miscalibrate and <em>that</em> is unfair. Policeman should be allowed to use their reason with all the information available to them, and people should be protected by the law and their rights.</p>
      <blockquote>
        <p>In the medical case, black women have higher obesity rates than other demographics. You still shouldn't treat a black woman as though she is a little bit obese if she isn't.</p>
      </blockquote>
      <p>Ummm... if a doctor has a black woman as a patient, yes, that doctor should look at whether the patient is <em>actually</em> obese rather than seeing on the chart that she is a black woman and assuming she's obese. The doctor should also, routinely, do lots of other things which they might not necessarily do, such as auscultation and palpation as part of a physical exam, but I think it would take a truly exceptionally lazy doctor to not even <em>look</em> at the patient. Obesity is really easy to tell. You can get more accurate by measuring the patient's weight, height and BMI, and then increasingly more accurate with sophisticated body-fat percentage measurements, but <em>a lot</em> of information can be gained very quickly just by looking at the patient and asking "are they fat?" If, for some bizarre reason, the doctor couldn't physically examine the patient, couldn't look at them, and couldn't ask them, then the doctor would be justified in assuming the patient were at least a little obese, or, rather, taking into account the probability distribution of their obesity based on the information they had for future inferences. The point is to use <em>all available</em> information to the fullest extent possible, if the patient is there and the doctor can quickly examine them and determine their obesity, then even an imperfect measurement d-separates "black woman" from "obesity". If they don't do that then they're ignoring information, which is bad.</p>
    </div>
  </body>
</post>