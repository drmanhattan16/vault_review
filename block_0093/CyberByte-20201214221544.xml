<post>
  <author>CyberByte</author>
  <date>2020-12-14T22:15:44Z</date>
  <link>/r/TheMotte/comments/kcsx2u/culture_war_roundup_for_the_week_of_december_14/gfuwaum/</link>
  <title>/u/CyberByte on Dr. Timnit Gebru's termination by Google and the putative racism of our machine-mind overlords</title>
  <body>
    <div class="md">
      <blockquote>
        <p>Could you summarize breifly...</p>
      </blockquote>
      <p>Also tagging <a href="/u/Gen_McMuster">/u/Gen_McMuster</a> and <a href="/u/PontifexMini">/u/PontifexMini</a> for asking similar questions and <a href="/u/1xKzERRdLm">/u/1xKzERRdLm</a> to correct me if necessary.</p>
      <p>Disclosure: I'm pretty anti-Gebru. I think the <a href="https://www.reddit.com/r/MachineLearning/comments/k77sxz/d_timnit_gebru_and_google_megathread/">megathread</a> on <a href="/r/MachineLearning">/r/MachineLearning</a> has most of the relevant links. </p>
      <p>Dr. Timnit Gebru is a leading figure in the AI Ethics research community, and also a black woman (I wish this wasn't relevant). She is also somewhat notorious for attacking other researchers (mostly on Twitter but also at e.g. conferences) for the racism, sexism, etc. she perceives in them and the field as a whole. Her background is technical, but my personal perception is that it might as well (also) be in critical race theory and/or gender studies. </p>
      <p>The current controversy is over the termination of Gebru's employment at Google. What we know is that Gebru co-wrote a paper where she's critical of the environmental impact of training large AI models and the bias in language models (such as BERT and GPT-3 if that means anything to you). This also seems to implicate Google (possibly among other players). Google has a process where employees have to submit papers they want to publish for internal review beforehand. Officially that has to happen 2 weeks before publication, she submitted it one day beforehand, got a quick green light, but later (presumably after actually looking at the paper) Google rescinded that somewhat. It's not entirely clear to me what happened here: I recall that she said she was ordered to withdraw the paper and could not get feedback, but then she also talks about what the feedback was. Basically, Google wanted her to add some discussion of existing efforts to combat/mitigate the problems she was talking about. There seems to be a lot of discussion about how reasonable/immoral Google was in asking/demanding this. In any case, it resulted in a conflict.</p>
      <p>At some point Gebru sent a message to Google's Brain Women and Allies listserv (linked in the megathread) where she vents about the situation in an allegedly (IMO: definitely) unprofessional way and may be calling on her colleagues to stop doing part of their work (namely on diversity, equity and inclusivity initiatives, because she thinks it's hopeless anyway). At some point she also sent <em>another</em> e-mail to her boss (or boss's boss?) Megan Kacholia in which she apparently put an ultimatum that she was going to resign if some demands weren't met (I think the demands included knowing who reviewed her paper). Kacholia replied with something along the lines of "We're not meeting your demands, accept your resignation and have decided that it should be today". So Google says Gebru resigned, and Gebru went to Twitter to talk about how Jeff Dean (Kacholia's boss I think) fired her. Jeff Dean is an absolute superstar within Google: tenth employee of the company, that <a href="/r/ML">/r/ML</a> thread likens his technical chops to Linus Torvalds and John Carmack, widely regarded to be an absolute sweetheart, and also a white man. </p>
      <hr />
      <p>I think this has become a huge shitstorm because it fits perfectly into the culture war. AI is supposedly sexist and racist, and here is another example because a black woman was fired. Furthermore, it looks like Google is just playing lip service to AI Ethics, terminating researchers as soon as they write something that's bad for PR. I thought this was pretty much the only perspective on Twitter until I saw the OP link to Pedro Domingos.</p>
      <p>On the other hand there's pushback from (I think mostly anonymous) people. Some of it is supposedly "common sense" like "what do you expect when openly criticizing your employer" or "don't give your employer an ultimatum". My personal impression is that Gebru is an absolutely toxic person, and I find it very understandable that any employer would jump at the opportunity to get rid of such an employee. I also suspect she would use her Twitter platform and community standing to bully and/or cancel whoever criticized her paper, so I understand that Google didn't want to give in to such a demand (and this possibly also explains other odd behaviors like giving the feedback through HR or something like that). </p>
      <p>I think AI Ethics is very important. I've dabbled in it and considered moving my career in that direction. However, I also get the strong impression that it's well on its way to being entirely captured by woke critical race theory feminist social justice warriors (pick your term) who think everything is racist/sexist/etc. and white men like me are all that is wrong with the world and the field of AI. And maybe people like me don't only fear that AI Ethics will be captured in this way, but that the whole field of AI will follow. And to those people, Gebru getting fired may read as a small victory. At the same time, it's very possible that she and her comrades come out of this stronger, as this fits their narrative very well, which may also be why others think it's important to push back against that and argue that she was actually fired for legitimate reasons.</p>
    </div>
  </body>
</post>